# ğŸ™ï¸ VALL-E-X Voice Cloning System  
### _High-Fidelity Neural Text-to-Speech with Advanced Speaker Similarity_

---

## ğŸŒŸ **Project Overview**

**> ğŸš€ This project is built on top of an **unofficial Microsoft-released implementation of VALL-E-X**, enhanced with **additional features, quality improvements, and evaluation metrics**.**

The system delivers **high-quality voice cloning** with strong **speaker identity preservation** and **word-level accuracy**, making it suitable for advanced **text-to-speech research and experimentation**.

### âœ¨ **Key Highlights**

- ğŸ§  **Better voice cloning quality** with improved speaker similarity  
- ğŸ¯ **High word-level accuracy metrics** for speech evaluation  
- ğŸ—£ï¸ **Speaker diarization** support  
- ğŸ” **Audio validation & vocal similarity analysis**  
- â–¶ï¸ **Play & download options** for generated audio output  
- ğŸµ Supports **`.wav` and `.mp3`** input audio formats  
- âš¡ Optimized inference pipeline for cleaner and more stable outputs  


---

## ğŸ”§ **Installation & Setup**

### ğŸ“¥ **1. Clone the Repository**


git clone <your_repo_url_here>

cd <your_repo_name>

### ğŸ **2. Python Requirements**


Python Version: 3.11

Recommended: Anaconda / Miniconda

## ğŸ“¦ **3. Create & Activate Conda Environment (Recommended)**

### Install Anaconda (If Not Installed)

Download Anaconda from:  
ğŸ‘‰ https://www.anaconda.com/products/distribution

During installation:
- âœ… **Check**: *Add Anaconda to PATH*
- âœ… **Check**: *Register Anaconda as default Python*

After installation, open **Anaconda Prompt** or terminal and verify:

conda --version

**Creating the anaconda environment (Put the command in cmd prompt)**

conda create -n <put_your_env_name> python=3.11

conda activate <put_your_env_name>

ğŸ“Œ Example:

conda create -n valle-env python=3.11

conda activate valle-env

**OR**

**ğŸ§ª Alternative: Python Virtual Environment (venv)**

If you do not want to use Conda, you can use Pythonâ€™s built-in virtual environment.

ğŸ”¹ Step 1: Ensure Python 3.11 is Installed

python --version

If not installed, download from:

ğŸ‘‰ https://www.python.org/downloads/

âš ï¸ Make sure Python is added to PATH during installation

ğŸ”¹ Step 2: Create Virtual Environment

python -m venv venv

ğŸ”¹ Step 3: Activate Virtual Environment

Windows

venv\Scripts\activate


macOS / Linux

source venv/bin/activate


âœ… After activation, you should see (venv) in your terminal.

### ğŸµ **4. Install FFmpeg (Required for recording of audio)**

FFmpeg is required for audio processing and format handling.

ğŸªŸ Windows

Download from:

ğŸ‘‰ https://www.gyan.dev/ffmpeg/builds/

ffmpeg-2025-12-07-git-c4d22f2d2c-full_build.7z

After downloading:

Extract the archive

Add the bin/ folder to your System PATH

ğŸ macOS

brew install ffmpeg

ğŸ§ Linux

sudo apt update

sudo apt install ffmpeg

âœ… Verify installation:

ffmpeg -version


### ğŸ“¥ **5. Install Python Dependencies**

Make sure your environment is activated, then run:

pip install -r requirements.txt

### â–¶ï¸ **6. Running the Model**

**RUN**

python launch-ui.py


ğŸ™ï¸ Input Audio Requirements

Supported formats: .wav, .mp3

Mono channel preferred

6-10 seconds of clean reference audio works best

500 - 600 characters text works best

ğŸ“¤ Output

The system generates:

ğŸ”Š Synthesized speech (.wav)

ğŸ“Š Word accuracy metrics

ğŸ§  Speaker similarity scores

â–¶ï¸ Audio playback & download options


## âš ï¸ Troubleshooting & Notes

> **Note:** If the system encounters an unknown or transient error, restarting the system is recommended, as it often resolves the issue.

- Ensure FFmpeg is correctly installed and added to PATH  
- Make sure the correct Conda / virtual environment is activated  
- Close and relaunch the UI if audio playback fails  
- Restart the system before deeper debugging if unexpected errors occur
  

### **ğŸ“ Project Structure**

```text
â”œâ”€â”€ customs/               # Custom user-defined components & overrides
â”œâ”€â”€ data/                  # Dataset files and intermediate data
â”œâ”€â”€ images/                # Images used for UI / documentation
â”œâ”€â”€ models/                # Core model architectures
â”œâ”€â”€ modules/               # Modularized model & pipeline components
â”œâ”€â”€ nltk_data/             # NLTK resources required for text processing
â”œâ”€â”€ presets/               # Predefined configuration presets
â”œâ”€â”€ prompts/               # Prompt templates for inference
â”œâ”€â”€ utils/                 # Utility functions and helpers              
â”œâ”€â”€ descriptions.py        # Model / feature descriptions
â”œâ”€â”€ examples.py            # Example usage scripts
â”œâ”€â”€ launch-ui.py           # Main entry point to launch UI & inference
â”œâ”€â”€ macros.py              # Global macros and constants
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```


